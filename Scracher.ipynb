{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4afbe97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----Categorias-----\n",
      "\n",
      "all books\n",
      "Travel\n",
      "Mystery\n",
      "Historical Fiction\n",
      "Sequential Art\n",
      "Classics\n",
      "Philosophy\n",
      "Romance\n",
      "Womens Fiction\n",
      "Fiction\n",
      "Childrens\n",
      "Religion\n",
      "Nonfiction\n",
      "Music\n",
      "Default\n",
      "Science Fiction\n",
      "Sports and Games\n",
      "Add a comment\n",
      "Fantasy\n",
      "New Adult\n",
      "Young Adult\n",
      "Science\n",
      "Poetry\n",
      "Paranormal\n",
      "Art\n",
      "Psychology\n",
      "Autobiography\n",
      "Parenting\n",
      "Adult Fiction\n",
      "Humor\n",
      "Horror\n",
      "History\n",
      "Food and Drink\n",
      "Christian Fiction\n",
      "Business\n",
      "Biography\n",
      "Thriller\n",
      "Contemporary\n",
      "Spirituality\n",
      "Academic\n",
      "Self Help\n",
      "Historical\n",
      "Christian\n",
      "Suspense\n",
      "Short Stories\n",
      "Novels\n",
      "Health\n",
      "Politics\n",
      "Cultural\n",
      "Erotica\n",
      "Crime\n",
      "\n",
      "CATEGORY: Crime\n",
      "\n",
      "-----Starting-----\n",
      "\n",
      "1 : new Book : The Long Shadow of Small Ghosts: Murder and Memory in an American City\n",
      "\n",
      "-----Done-----\n"
     ]
    }
   ],
   "source": [
    "# ------- Scraper ------\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "\n",
    "cache_autores = {}\n",
    "def obtener_autor(titulo):\n",
    "\n",
    "    if titulo in cache_autores:\n",
    "        return cache_autores[titulo]\n",
    "    \n",
    "    url_api = \"https://openlibrary.org/search.json\"\n",
    "    params = {'title' : titulo}\n",
    "\n",
    "    try:\n",
    "        respuesta = requests.get(url_api, params=params, timeout=5)\n",
    "        if respuesta.status_code == 200:\n",
    "            data = respuesta.json()\n",
    "            if data.get(\"numFound\",0) > 0:\n",
    "                autor = data[\"docs\"][0].get(\"author_name\", [\"desconocido\"])[0]\n",
    "            else:\n",
    "                autor = \"desconocido\"\n",
    "        else:\n",
    "            autor = 'error de API'\n",
    "    except Exception as e:\n",
    "        autor = \"Error\"\n",
    "    \n",
    "    cache_autores[titulo] = autor\n",
    "    time.sleep(1)\n",
    "    return autor\n",
    "\n",
    "\n",
    "url = 'https://books.toscrape.com/'\n",
    "respuesta = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(respuesta.content, 'lxml')\n",
    "\n",
    "etiqueta_categorias = soup.find('ul', class_='nav nav-list')\n",
    "\n",
    "# ----- diccionario para guardar links segun categoria -----\n",
    "category = {}\n",
    "\n",
    "# ----- para todos los libros -----\n",
    "link_all_books = url + etiqueta_categorias.a['href']\n",
    "category['all books'] = link_all_books\n",
    "\n",
    "# ----- por categorias -----\n",
    "etiqueta_book_category = etiqueta_categorias.find('ul')\n",
    "book_category = etiqueta_book_category.find_all('li')\n",
    "for cat in book_category:\n",
    "    nombre = cat.a.text.strip()\n",
    "    link = cat.a['href']\n",
    "    category[nombre] = url + link \n",
    "\n",
    "print(\"\\n-----Categorias-----\\n\")\n",
    "for x in category:\n",
    "    print(x)\n",
    "category_eleccion = input('categoria a visitar: ')\n",
    "print(f\"\\nCATEGORY: {category_eleccion}\")\n",
    "\n",
    "if category_eleccion in category:\n",
    "\n",
    "    print(\"\\n-----Starting-----\\n\")\n",
    "    new_url = category[category_eleccion]\n",
    "    new_response = requests.get(new_url)\n",
    "    \n",
    "    books_category = []\n",
    "    book_counter = 0\n",
    "\n",
    "    while True:\n",
    "        soup_new = BeautifulSoup(new_response.content, 'lxml')\n",
    "\n",
    "        seleccion_of_books = soup_new.find('ol', class_='row')\n",
    "        all_books_seleccion = seleccion_of_books.find_all('li')\n",
    "\n",
    "        for book in all_books_seleccion:\n",
    "\n",
    "            book_information = book.find('article', class_='product_pod')\n",
    "\n",
    "            # ---- nombre del libro -----\n",
    "            title = book_information.h3.a['title']\n",
    "\n",
    "            # ---- autor del libro -----\n",
    "            autor = obtener_autor(title)\n",
    "\n",
    "            # ---- precio del libro -----\n",
    "            price_tag = book_information.find('div', class_='product_price')\n",
    "            price = price_tag.find('p', class_='price_color').text\n",
    "\n",
    "            # ---- disponibilidad del libro ----\n",
    "            disponibility_tag = price_tag.find('p', class_='instock availability')\n",
    "            disponibility = disponibility_tag.text.strip()\n",
    "\n",
    "            # ----- cantidad de estrellas -----\n",
    "            stars_tag = book_information.find('p', class_='star-rating')\n",
    "            stars = stars_tag['class'][1] if stars_tag else 'not reviewd'\n",
    "\n",
    "            # ----- descripcion -----\n",
    "            description_place_tag_link = book_information.h3.a['href']\n",
    "            description_place_tag_complete_link = urljoin(new_url, description_place_tag_link)\n",
    "            description_response = requests.get(description_place_tag_complete_link)\n",
    "            soup_description = BeautifulSoup(description_response.content, 'lxml')\n",
    "            product_tag = soup_description.find('div', id='product_description')\n",
    "            if product_tag:\n",
    "                des_tag = product_tag.find_next_sibling('p')\n",
    "                if des_tag:\n",
    "                    description = des_tag.text.replace('\\n', ' ').strip()\n",
    "            else:\n",
    "                description = 'No description'\n",
    "\n",
    "            books_category.append({\n",
    "                'title' : title,\n",
    "                'author' : autor,\n",
    "                'stars' : stars,\n",
    "                'price' : price,\n",
    "                'stock' : disponibility,\n",
    "                'description' : description\n",
    "            })\n",
    "            \n",
    "            book_counter += 1\n",
    "            print(book_counter, ': new Book :', title)\n",
    "        \n",
    "        # ----- si hay mas de una pagina en el apartado -----\n",
    "        next_tag = soup_new.find('li', class_='next')\n",
    "\n",
    "\n",
    "        # ----- si hay volver a hacerel requests y trabajar con el siguiente HTML -----\n",
    "        if next_tag:\n",
    "            try:\n",
    "                next_link = next_tag.a['href']\n",
    "                new_url = urljoin(new_url, next_link)\n",
    "                new_response = requests.get(new_url)\n",
    "            except Exception as e:\n",
    "                print(\"---- No more to analyse ----\")\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    print(\"\\n-----Done-----\")\n",
    "# terminando esto todo eta en la lista Books -----> primera parte del scraper lista\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44d25de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base de datos creada\n"
     ]
    }
   ],
   "source": [
    "# ---- base de datos MySql ----\n",
    "import sqlite3\n",
    "\n",
    "# ----- iniciar conexion con base de datos -----\n",
    "conexion = sqlite3.connect('books_data_2.db')\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "# ---- Crear Tablas -----\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Categoria (\n",
    "    id_category INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    name TEXT UNIQUE\n",
    ");\n",
    " \"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Autor (\n",
    "    id_author INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    author TEXT UNIQUE\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS Libro (\n",
    "    id_book INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    title TEXT NOT NULL,\n",
    "    price REAL,\n",
    "    stars INTEGER,\n",
    "    stock TEXT,\n",
    "    description TEXT,\n",
    "    id_category INTEGER,\n",
    "    UNIQUE(title, id_category),\n",
    "    FOREIGN KEY (id_category) REFERENCES Categoria(id_category)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS LibroAutor (\n",
    "    id_book INTEGER,\n",
    "    id_author INTEGER,\n",
    "    PRIMARY KEY (id_book, id_author),\n",
    "    FOREIGN KEY (id_book) REFERENCES Libro(id_book),\n",
    "    FOREIGN KEY (id_author) REFERENCES Autor(id_author)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "conexion.commit()\n",
    "conexion.close()\n",
    "\n",
    "print(\"base de datos creada\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f26bc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CATEGORY: Crime\n",
      "\n",
      "AGREGADO: The Long Shadow of Small Ghosts: Murder and Memory in an American City\n",
      "\n",
      " Datos insertados correctamente en la base de datos.\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# ----- iniciar conexion -----\n",
    "conexion = sqlite3.connect('books_data_2.db')\n",
    "cursor = conexion.cursor()\n",
    "\n",
    "category_list_books = category_eleccion.strip().lower()\n",
    "\n",
    "print(f\"CATEGORY: {category_eleccion}\\n\")\n",
    "cursor.execute(\"INSERT OR IGNORE INTO Categoria (name) VALUES (?)\", (category_eleccion,))\n",
    "conexion.commit()\n",
    "\n",
    "cursor.execute(\"SELECT id_category FROM Categoria WHERE name = ?\", (category_eleccion,))\n",
    "id_category = cursor.fetchone()[0]\n",
    "\n",
    "for book in books_category:\n",
    "    titulo = book['title']\n",
    "    autor = book['author']\n",
    "    estrellas = 0\n",
    "    try: \n",
    "        estrellas = [\"Zero\",\"One\",\"Two\",\"Three\",\"Four\",\"Five\"].index(book['stars'].capitalize())\n",
    "    except ValueError:\n",
    "        estrellas = None\n",
    "\n",
    "    precio = float(book['price'].replace('£','').strip()) if \"£\" in book['price'] else None\n",
    "    stock = book['stock']\n",
    "    descripcion = book['description']\n",
    "\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO Autor (author) VALUES (?)\", (autor,))\n",
    "    conexion.commit()\n",
    "\n",
    "    cursor.execute(\"SELECT id_author FROM Autor WHERE author = ?\", (autor,))\n",
    "    id_author = cursor.fetchone()[0]\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT OR IGNORE INTO Libro (title, price, stars, stock, description, id_category)\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "    \"\"\", (titulo, precio, estrellas, stock, descripcion, id_category))\n",
    "    conexion.commit()\n",
    "\n",
    "    id_libro = cursor.lastrowid\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT OR IGNORE INTO LibroAutor (id_book, id_author)\n",
    "        VALUES (?, ?)\n",
    "    \"\"\", (id_libro, id_author))\n",
    "    print(f\"AGREGADO: {titulo}\")\n",
    "\n",
    "conexion.commit()\n",
    "conexion.close()\n",
    "\n",
    "print(\"\\n Datos insertados correctamente en la base de datos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
